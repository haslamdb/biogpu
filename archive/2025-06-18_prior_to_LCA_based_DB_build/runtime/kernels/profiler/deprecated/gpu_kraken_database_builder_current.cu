// gpu_kraken2_database_builder_integrated.cu
// COMPLETE INTEGRATED VERSION: GPU-accelerated Kraken2-style database builder
// Combines the infrastructure from the original with the correct minimizer extraction from the fixed version

#include <cuda_runtime.h>
#include <thrust/device_vector.h>
#include <thrust/host_vector.h>
#include <thrust/sort.h>
#include <thrust/unique.h>
#include <thrust/reduce.h>
#include <thrust/scan.h>
#include <cub/cub.cuh>
#include <iostream>
#include <fstream>
#include <vector>
#include <unordered_map>
#include <filesystem>
#include <chrono>
#include <algorithm>
#include <string>
#include <sstream>
#include <regex>
#include <iomanip>

// Configuration - Conservative memory settings
#define MAX_GENOMES_PER_BATCH 25
#define MAX_MINIMIZERS_PER_BATCH 1000000  // 1M minimizers max
#define MAX_SEQUENCE_LENGTH 20000000      // 20MB max per batch
#define THREADS_PER_BLOCK 256

// Kraken2-style parameters
struct MinimizerParams {
    int k = 35;              // k-mer length (Kraken2 default)
    int ell = 31;            // minimizer length (Kraken2 default)
    int spaces = 7;          // spaced seed parameter
    uint64_t xor_mask = 0;   // XOR mask for hash shuffling
    
    static MinimizerParams kraken2_defaults() {
        MinimizerParams p;
        p.k = 35;
        p.ell = 31;
        p.spaces = 7;
        p.xor_mask = 0x3c8bfbb395c60474ULL;  // Random mask for better distribution
        return p;
    }
};

// Structure definitions
struct GPUGenomeInfo {
    uint32_t taxon_id;
    uint32_t sequence_offset;
    uint32_t sequence_length;
    uint32_t genome_id;
};

struct GPUMinimizerHit {
    uint64_t minimizer_hash;
    uint32_t taxon_id;
    uint32_t position;
    uint32_t genome_id;
};

struct LCACandidate {
    uint64_t minimizer_hash;
    uint32_t lca_taxon;
    uint32_t genome_count;
    float uniqueness_score;
};

struct GPUBuildStats {
    uint64_t total_sequences;
    uint64_t total_bases;
    uint64_t total_kmers_processed;
    uint64_t valid_minimizers_extracted;
    uint64_t unique_minimizers;
    uint64_t lca_assignments;
    double sequence_processing_time;
    double minimizer_extraction_time;
    double lca_computation_time;
    double database_construction_time;
};

// Error checking macro
#define CUDA_CHECK(call) do { \
    cudaError_t error = call; \
    if (error != cudaSuccess) { \
        fprintf(stderr, "CUDA error at %s:%d - %s\n", __FILE__, __LINE__, \
                cudaGetErrorString(error)); \
        exit(1); \
    } \
} while(0)

// ================================================================
// DEVICE FUNCTIONS FOR KRAKEN2-STYLE MINIMIZER EXTRACTION
// ================================================================

__device__ uint64_t encode_base_kraken2(char base) {
    switch (base) {
        case 'A': case 'a': return 0;
        case 'C': case 'c': return 1;
        case 'G': case 'g': return 2;
        case 'T': case 't': return 3;
        default: return 4;  // Invalid base marker
    }
}

__device__ uint64_t hash_lmer_kraken2(const char* sequence, int pos, int ell) {
    uint64_t hash = 0;
    for (int i = 0; i < ell; i++) {
        uint64_t base = encode_base_kraken2(sequence[pos + i]);
        if (base == 4) return UINT64_MAX;  // Invalid sequence
        hash = (hash << 2) | base;
    }
    return hash;
}

__device__ uint64_t reverse_complement_hash(uint64_t hash, int len) {
    uint64_t rc = 0;
    for (int i = 0; i < len; i++) {
        uint64_t base = (hash >> (2 * i)) & 3;
        uint64_t rc_base = 3 - base;  // A<->T, C<->G
        rc = (rc << 2) | rc_base;
    }
    return rc;
}

__device__ uint64_t canonical_hash(uint64_t hash, int len) {
    uint64_t rc = reverse_complement_hash(hash, len);
    return (hash < rc) ? hash : rc;
}

__device__ uint64_t apply_spaced_seed_mask(uint64_t hash, int spaces, int ell) {
    if (spaces == 0) return hash;
    
    uint64_t masked_hash = 0;
    int out_pos = 0;
    
    // Apply spaced seed pattern: keep every (spaces+1)th position
    for (int i = 0; i < ell; i++) {
        if (i % (spaces + 1) == 0) {
            uint64_t base = (hash >> (2 * (ell - 1 - i))) & 3;
            masked_hash |= (base << (2 * out_pos));
            out_pos++;
        }
    }
    
    return masked_hash;
}

__device__ bool is_valid_kmer_sequence(const char* seq, int pos, int len) {
    for (int i = 0; i < len; i++) {
        char c = seq[pos + i];
        if (c != 'A' && c != 'C' && c != 'G' && c != 'T' &&
            c != 'a' && c != 'c' && c != 'g' && c != 't') {
            return false;
        }
    }
    return true;
}

// CRITICAL: Proper Kraken2-style minimizer extraction with sliding window
__device__ uint64_t extract_minimizer_kraken2_style(
    const char* sequence,
    int kmer_pos,
    int k,
    int ell,
    int spaces,
    uint64_t xor_mask) {
    
    // Check if entire k-mer is valid
    if (!is_valid_kmer_sequence(sequence, kmer_pos, k)) {
        return UINT64_MAX;
    }
    
    uint64_t min_hash = UINT64_MAX;
    
    // Sliding window within the k-mer to find the true minimizer
    for (int i = 0; i <= k - ell; i++) {
        uint64_t lmer_hash = hash_lmer_kraken2(sequence, kmer_pos + i, ell);
        if (lmer_hash == UINT64_MAX) continue;
        
        // Get canonical hash (lexicographically smaller of forward and reverse complement)
        uint64_t canonical = canonical_hash(lmer_hash, ell);
        
        // Apply spaced seed mask if enabled
        if (spaces > 0) {
            canonical = apply_spaced_seed_mask(canonical, spaces, ell);
        }
        
        // Apply XOR shuffling to avoid bias
        canonical ^= xor_mask;
        
        // Keep track of minimum
        if (canonical < min_hash) {
            min_hash = canonical;
        }
    }
    
    return min_hash;
}

// ================================================================
// GPU KERNELS
// ================================================================

// FIXED: Kraken2-style minimizer extraction kernel with proper compression
__global__ void extract_minimizers_kraken2_kernel(
    const char* sequence_data,
    const GPUGenomeInfo* genome_info,
    int num_genomes,
    GPUMinimizerHit* minimizer_hits,
    uint32_t* global_hit_counter,
    MinimizerParams params,
    int max_minimizers) {
    
    int genome_id = blockIdx.x;
    if (genome_id >= num_genomes) return;
    
    // CRITICAL: Only use thread 0 to ensure sequential processing and proper deduplication
    if (threadIdx.x != 0) return;
    
    const GPUGenomeInfo& genome = genome_info[genome_id];
    const char* sequence = sequence_data + genome.sequence_offset;
    uint32_t seq_length = genome.sequence_length;
    
    if (seq_length < params.k) return;
    
    uint64_t last_minimizer = UINT64_MAX;  // KEY: Track last minimizer for compression
    uint32_t local_count = 0;
    uint32_t total_kmers = seq_length - params.k + 1;
    
    // Process each k-mer sequentially
    for (uint32_t kmer_pos = 0; kmer_pos < total_kmers; kmer_pos++) {
        uint64_t minimizer = extract_minimizer_kraken2_style(
            sequence, kmer_pos, params.k, params.ell, params.spaces, params.xor_mask
        );
        
        if (minimizer != UINT64_MAX) {
            // CRITICAL: Only store if different from previous minimizer (Kraken2 compression!)
            if (minimizer != last_minimizer) {
                uint32_t global_pos = atomicAdd(global_hit_counter, 1);
                
                if (global_pos < max_minimizers) {
                    GPUMinimizerHit hit;
                    hit.minimizer_hash = minimizer;
                    hit.taxon_id = genome.taxon_id;
                    hit.position = kmer_pos;
                    hit.genome_id = genome.genome_id;
                    
                    minimizer_hits[global_pos] = hit;
                    local_count++;
                } else {
                    // Hit limit, stop processing
                    break;
                }
                
                last_minimizer = minimizer;
            }
            // If minimizer == last_minimizer, skip it (this creates the compression!)
        }
    }
}

// Kernel to convert hits to LCA candidates
__global__ void convert_hits_to_lca_candidates(
    const GPUMinimizerHit* hits,
    int num_hits,
    LCACandidate* candidates) {
    
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx >= num_hits) return;
    
    const GPUMinimizerHit& hit = hits[idx];
    LCACandidate& candidate = candidates[idx];
    
    candidate.minimizer_hash = hit.minimizer_hash;
    candidate.lca_taxon = hit.taxon_id;
    candidate.genome_count = 1;  // Will be updated during final merge
    candidate.uniqueness_score = 1.0f;
}

// ================================================================
// HOST-SIDE DATABASE BUILDER CLASS
// ================================================================

class GPUKraken2DatabaseBuilder {
private:
    std::string output_directory;
    MinimizerParams params;
    
    // Host data
    std::vector<std::string> genome_files;
    std::vector<uint32_t> genome_taxon_ids;
    std::unordered_map<uint32_t, std::string> taxon_names;
    std::unordered_map<uint32_t, uint32_t> taxon_parents;
    std::vector<LCACandidate> all_lca_candidates;
    
    // GPU memory
    char* d_sequence_data;
    GPUGenomeInfo* d_genome_info;
    GPUMinimizerHit* d_minimizer_hits;
    uint32_t* d_global_counter;
    LCACandidate* d_lca_candidates;
    
    // Statistics
    GPUBuildStats stats;
    
public:
    GPUKraken2DatabaseBuilder(const std::string& output_dir,
                              const MinimizerParams& config = MinimizerParams::kraken2_defaults())
        : output_directory(output_dir), params(config),
          d_sequence_data(nullptr), d_genome_info(nullptr),
          d_minimizer_hits(nullptr), d_global_counter(nullptr),
          d_lca_candidates(nullptr) {
        
        std::cout << "Initializing GPU Kraken2 database builder..." << std::endl;
        std::cout << "Parameters: k=" << params.k << ", ell=" << params.ell 
                  << ", spaces=" << params.spaces << std::endl;
        
        std::filesystem::create_directories(output_directory);
        check_and_adjust_memory();
        memset(&stats, 0, sizeof(stats));
    }
    
    ~GPUKraken2DatabaseBuilder() {
        free_gpu_memory();
    }
    
    bool build_database_from_genomes(
        const std::string& genome_library_path,
        const std::string& taxonomy_path = "") {
        
        std::cout << "\n=== BUILDING KRAKEN2-STYLE DATABASE ===" << std::endl;
        auto total_start = std::chrono::high_resolution_clock::now();
        
        if (!load_genome_files(genome_library_path)) {
            std::cerr << "Failed to load genome files" << std::endl;
            return false;
        }
        
        if (!taxonomy_path.empty()) {
            if (!load_taxonomy_data(taxonomy_path)) {
                std::cerr << "Warning: Failed to load taxonomy data" << std::endl;
            }
        }
        
        if (!process_genomes_gpu()) {
            std::cerr << "Failed to process genomes on GPU" << std::endl;
            return false;
        }
        
        if (!save_database()) {
            std::cerr << "Failed to save database" << std::endl;
            return false;
        }
        
        auto total_end = std::chrono::high_resolution_clock::now();
        auto total_duration = std::chrono::duration_cast<std::chrono::seconds>(total_end - total_start);
        
        std::cout << "\n=== DATABASE BUILD COMPLETE ===" << std::endl;
        std::cout << "Total build time: " << total_duration.count() << " seconds" << std::endl;
        print_build_statistics();
        
        return true;
    }
    
    void set_batch_size(int genomes_per_batch) {
        if (genomes_per_batch > 0 && genomes_per_batch <= 100) {
            // Update the global constant would require recompilation
            std::cout << "Note: Batch size is compile-time constant. Current: " 
                      << MAX_GENOMES_PER_BATCH << " genomes" << std::endl;
        }
    }
    
    void print_build_statistics() {
        std::cout << "\n=== BUILD STATISTICS ===" << std::endl;
        std::cout << "Total sequences processed: " << stats.total_sequences << std::endl;
        std::cout << "Total bases processed: " << stats.total_bases << std::endl;
        std::cout << "Valid minimizers extracted: " << stats.valid_minimizers_extracted << std::endl;
        std::cout << "Unique minimizers: " << stats.unique_minimizers << std::endl;
        std::cout << "LCA assignments computed: " << stats.lca_assignments << std::endl;
        
        if (stats.total_kmers_processed > 0) {
            double compression_ratio = (double)stats.valid_minimizers_extracted / stats.total_kmers_processed;
            std::cout << "Compression ratio: " << std::fixed << std::setprecision(4) 
                      << compression_ratio << " (" << std::fixed << std::setprecision(1) 
                      << (1.0/compression_ratio) << "x reduction)" << std::endl;
        }
        
        std::cout << "Processing times:" << std::endl;
        std::cout << "  Sequence processing: " << std::fixed << std::setprecision(2) 
                  << stats.sequence_processing_time << "s" << std::endl;
        std::cout << "  Minimizer extraction: " << std::fixed << std::setprecision(2) 
                  << stats.minimizer_extraction_time << "s" << std::endl;
        
        if (stats.total_bases > 0) {
            double bases_per_second = stats.total_bases / (stats.sequence_processing_time + stats.minimizer_extraction_time);
            std::cout << "Processing rate: " << std::scientific << std::setprecision(2) 
                      << bases_per_second << " bases/second" << std::endl;
        }
    }
    
private:
    void check_and_adjust_memory() {
        size_t free_mem, total_mem;
        cudaMemGetInfo(&free_mem, &total_mem);
        
        std::cout << "GPU Memory: " << (free_mem / 1024 / 1024) << " MB free / " 
                  << (total_mem / 1024 / 1024) << " MB total" << std::endl;
        
        size_t sequence_memory = MAX_GENOMES_PER_BATCH * MAX_SEQUENCE_LENGTH;
        size_t minimizer_memory = MAX_MINIMIZERS_PER_BATCH * sizeof(GPUMinimizerHit);
        size_t total_needed = sequence_memory + minimizer_memory + 
                             MAX_GENOMES_PER_BATCH * sizeof(GPUGenomeInfo) +
                             MAX_MINIMIZERS_PER_BATCH * sizeof(LCACandidate);
        
        std::cout << "Required memory: " << (total_needed / 1024 / 1024) << " MB" << std::endl;
        
        if (total_needed > free_mem * 0.8) {
            std::cout << "WARNING: May not have enough GPU memory. Consider reducing batch sizes." << std::endl;
        }
    }
    
    bool allocate_gpu_memory() {
        std::cout << "Allocating GPU memory..." << std::endl;
        
        size_t sequence_memory = MAX_GENOMES_PER_BATCH * MAX_SEQUENCE_LENGTH;
        size_t genome_info_memory = MAX_GENOMES_PER_BATCH * sizeof(GPUGenomeInfo);
        size_t minimizer_memory = MAX_MINIMIZERS_PER_BATCH * sizeof(GPUMinimizerHit);
        size_t candidate_memory = MAX_MINIMIZERS_PER_BATCH * sizeof(LCACandidate);
        
        std::cout << "Memory allocation:" << std::endl;
        std::cout << "  Sequences: " << (sequence_memory / 1024 / 1024) << " MB" << std::endl;
        std::cout << "  Minimizers: " << (minimizer_memory / 1024 / 1024) << " MB" << std::endl;
        
        CUDA_CHECK(cudaMalloc(&d_sequence_data, sequence_memory));
        CUDA_CHECK(cudaMalloc(&d_genome_info, genome_info_memory));
        CUDA_CHECK(cudaMalloc(&d_minimizer_hits, minimizer_memory));
        CUDA_CHECK(cudaMalloc(&d_global_counter, sizeof(uint32_t)));
        CUDA_CHECK(cudaMalloc(&d_lca_candidates, candidate_memory));
        
        return true;
    }
    
    void free_gpu_memory() {
        if (d_sequence_data) { cudaFree(d_sequence_data); d_sequence_data = nullptr; }
        if (d_genome_info) { cudaFree(d_genome_info); d_genome_info = nullptr; }
        if (d_minimizer_hits) { cudaFree(d_minimizer_hits); d_minimizer_hits = nullptr; }
        if (d_global_counter) { cudaFree(d_global_counter); d_global_counter = nullptr; }
        if (d_lca_candidates) { cudaFree(d_lca_candidates); d_lca_candidates = nullptr; }
    }
    
    bool load_genome_files(const std::string& library_path) {
        std::cout << "Loading genome files from: " << library_path << std::endl;
        
        genome_files = find_genome_files(library_path);
        
        if (genome_files.empty()) {
            std::cerr << "No genome files found in " << library_path << std::endl;
            return false;
        }
        
        genome_taxon_ids.reserve(genome_files.size());
        for (const auto& file : genome_files) {
            uint32_t taxon_id = extract_taxon_from_filename(file);
            genome_taxon_ids.push_back(taxon_id);
            
            if (taxon_names.find(taxon_id) == taxon_names.end()) {
                std::filesystem::path p(file);
                taxon_names[taxon_id] = p.stem().string();
            }
        }
        
        std::cout << "Found " << genome_files.size() << " genome files" << std::endl;
        stats.total_sequences = genome_files.size();
        
        return true;
    }
    
    bool process_genomes_gpu() {
        std::cout << "Processing genomes on GPU..." << std::endl;
        auto start_time = std::chrono::high_resolution_clock::now();
        
        if (!allocate_gpu_memory()) {
            return false;
        }
        
        for (size_t batch_start = 0; batch_start < genome_files.size(); 
             batch_start += MAX_GENOMES_PER_BATCH) {
            
            size_t batch_end = std::min(batch_start + MAX_GENOMES_PER_BATCH, genome_files.size());
            
            std::cout << "Processing batch " << (batch_start / MAX_GENOMES_PER_BATCH + 1) 
                      << ": genomes " << batch_start << "-" << (batch_end-1) << std::endl;
            
            if (!process_genome_batch(batch_start, batch_end)) {
                std::cerr << "Failed to process batch starting at " << batch_start << std::endl;
                return false;
            }
        }
        
        auto end_time = std::chrono::high_resolution_clock::now();
        stats.sequence_processing_time = 
            std::chrono::duration<double>(end_time - start_time).count();
        
        return true;
    }
    
    bool process_genome_batch(size_t batch_start, size_t batch_end) {
        // Load sequences for this batch
        std::string concatenated_sequences;
        std::vector<GPUGenomeInfo> genome_infos;
        
        uint32_t current_offset = 0;
        
        for (size_t i = batch_start; i < batch_end; i++) {
            auto sequences = load_sequences_from_fasta(genome_files[i]);
            
            for (const auto& seq : sequences) {
                if (seq.length() < params.k) continue;  // Skip too-short sequences
                
                GPUGenomeInfo info;
                info.taxon_id = genome_taxon_ids[i];
                info.sequence_offset = current_offset;
                info.sequence_length = seq.length();
                info.genome_id = i;
                
                genome_infos.push_back(info);
                concatenated_sequences += seq;
                current_offset += seq.length();
                stats.total_bases += seq.length();
                
                // Track k-mers
                if (seq.length() >= params.k) {
                    stats.total_kmers_processed += seq.length() - params.k + 1;
                }
                
                // Check memory limits
                if (current_offset > MAX_SEQUENCE_LENGTH) {
                    std::cout << "Reached sequence memory limit, processing partial batch" << std::endl;
                    break;
                }
            }
        }
        
        if (genome_infos.empty()) {
            std::cout << "No valid sequences in batch, skipping" << std::endl;
            return true;
        }
        
        std::cout << "  Loaded " << genome_infos.size() << " sequences (" 
                  << (concatenated_sequences.length() / 1024 / 1024) << " MB)" << std::endl;
        
        // Transfer to GPU
        CUDA_CHECK(cudaMemcpy(d_sequence_data, concatenated_sequences.c_str(),
                             concatenated_sequences.length(), cudaMemcpyHostToDevice));
        
        CUDA_CHECK(cudaMemcpy(d_genome_info, genome_infos.data(),
                             genome_infos.size() * sizeof(GPUGenomeInfo), cudaMemcpyHostToDevice));
        
        // Reset counter
        uint32_t zero = 0;
        CUDA_CHECK(cudaMemcpy(d_global_counter, &zero, sizeof(uint32_t), cudaMemcpyHostToDevice));
        
        // Extract minimizers
        auto extract_start = std::chrono::high_resolution_clock::now();
        
        extract_minimizers_kraken2_kernel<<<genome_infos.size(), 1>>>(
            d_sequence_data, d_genome_info, genome_infos.size(),
            d_minimizer_hits, d_global_counter, params, MAX_MINIMIZERS_PER_BATCH
        );
        
        CUDA_CHECK(cudaDeviceSynchronize());
        
        auto extract_end = std::chrono::high_resolution_clock::now();
        stats.minimizer_extraction_time += 
            std::chrono::duration<double>(extract_end - extract_start).count();
        
        // Get results
        uint32_t num_hits;
        CUDA_CHECK(cudaMemcpy(&num_hits, d_global_counter, sizeof(uint32_t), cudaMemcpyDeviceToHost));
        
        if (num_hits > 0) {
            std::cout << "  Extracted " << num_hits << " minimizers" << std::endl;
            
            // Convert to LCA candidates
            int blocks = (num_hits + THREADS_PER_BLOCK - 1) / THREADS_PER_BLOCK;
            convert_hits_to_lca_candidates<<<blocks, THREADS_PER_BLOCK>>>(
                d_minimizer_hits, num_hits, d_lca_candidates
            );
            CUDA_CHECK(cudaDeviceSynchronize());
            
            // Copy candidates back to host
            std::vector<LCACandidate> batch_candidates(num_hits);
            CUDA_CHECK(cudaMemcpy(batch_candidates.data(), d_lca_candidates,
                                 num_hits * sizeof(LCACandidate), cudaMemcpyDeviceToHost));
            
            // Accumulate candidates
            all_lca_candidates.insert(all_lca_candidates.end(), 
                                     batch_candidates.begin(), batch_candidates.end());
            
            std::cout << "  Created " << num_hits << " LCA candidates (total: " 
                      << all_lca_candidates.size() << ")" << std::endl;
        }
        
        stats.valid_minimizers_extracted += num_hits;
        stats.lca_assignments += num_hits;
        
        return true;
    }
    
    std::vector<std::string> find_genome_files(const std::string& directory) {
        std::vector<std::string> files;
        
        for (const auto& entry : std::filesystem::recursive_directory_iterator(directory)) {
            if (entry.is_regular_file()) {
                std::string extension = entry.path().extension().string();
                
                if (extension == ".fna" || extension == ".fa" || extension == ".fasta" ||
                    extension == ".ffn" || extension == ".faa") {
                    files.push_back(entry.path().string());
                }
            }
        }
        
        std::sort(files.begin(), files.end());
        return files;
    }
    
    uint32_t extract_taxon_from_filename(const std::string& filename) {
        std::filesystem::path p(filename);
        std::string stem = p.stem().string();
        
        // Look for taxid pattern
        std::regex taxid_pattern(R"(taxid[_-](\d+))");
        std::smatch match;
        if (std::regex_search(stem, match, taxid_pattern)) {
            return std::stoul(match[1].str());
        }
        
        // Look for GCF accession pattern
        std::regex gcf_pattern(R"(GCF_(\d+\.\d+))");
        if (std::regex_search(stem, match, gcf_pattern)) {
            std::hash<std::string> hasher;
            return hasher(match[1].str()) % 1000000 + 1000000;
        }
        
        // Fallback: hash the filename
        std::hash<std::string> hasher;
        return hasher(stem) % 1000000 + 2000000;
    }
    
    std::vector<std::string> load_sequences_from_fasta(const std::string& fasta_path) {
        std::vector<std::string> sequences;
        std::ifstream file(fasta_path);
        
        if (!file.is_open()) {
            std::cerr << "Cannot open FASTA file: " << fasta_path << std::endl;
            return sequences;
        }
        
        std::string line, current_sequence;
        bool in_sequence = false;
        
        while (std::getline(file, line)) {
            if (line.empty()) continue;
            
            if (line[0] == '>') {
                if (in_sequence && !current_sequence.empty()) {
                    sequences.push_back(current_sequence);
                    current_sequence.clear();
                }
                in_sequence = true;
            } else if (in_sequence) {
                current_sequence += line;
            }
        }
        
        if (!current_sequence.empty()) {
            sequences.push_back(current_sequence);
        }
        
        file.close();
        return sequences;
    }
    
    bool load_taxonomy_data(const std::string& taxonomy_path) {
        std::cout << "Loading taxonomy data from: " << taxonomy_path << std::endl;
        
        std::filesystem::path base_path(taxonomy_path);
        std::string nodes_file = base_path / "nodes.dmp";
        std::string names_file = base_path / "names.dmp";
        
        if (!std::filesystem::exists(nodes_file)) {
            std::cerr << "nodes.dmp not found at: " << nodes_file << std::endl;
            return false;
        }
        
        // Load taxonomy tree from nodes.dmp
        std::ifstream nodes_in(nodes_file);
        std::string line;
        int nodes_loaded = 0;
        
        while (std::getline(nodes_in, line)) {
            if (line.empty()) continue;
            
            std::istringstream iss(line);
            std::string token;
            std::vector<std::string> fields;
            
            while (std::getline(iss, token, '|')) {
                token.erase(0, token.find_first_not_of(" \t"));
                token.erase(token.find_last_not_of(" \t") + 1);
                fields.push_back(token);
            }
            
            if (fields.size() >= 2) {
                try {
                    uint32_t taxon_id = std::stoul(fields[0]);
                    uint32_t parent_id = std::stoul(fields[1]);
                    
                    taxon_parents[taxon_id] = parent_id;
                    nodes_loaded++;
                    
                    if (taxon_names.find(taxon_id) == taxon_names.end()) {
                        taxon_names[taxon_id] = "taxon_" + std::to_string(taxon_id);
                    }
                } catch (const std::exception& e) {
                    continue;
                }
            }
        }
        nodes_in.close();
        
        std::cout << "Loaded " << nodes_loaded << " taxonomy nodes" << std::endl;
        
        // Load scientific names from names.dmp
        if (std::filesystem::exists(names_file)) {
            std::ifstream names_in(names_file);
            int names_loaded = 0;
            
            while (std::getline(names_in, line)) {
                if (line.empty()) continue;
                
                std::istringstream iss(line);
                std::string token;
                std::vector<std::string> fields;
                
                while (std::getline(iss, token, '|')) {
                    token.erase(0, token.find_first_not_of(" \t"));
                    token.erase(token.find_last_not_of(" \t") + 1);
                    fields.push_back(token);
                }
                
                if (fields.size() >= 4) {
                    try {
                        uint32_t taxon_id = std::stoul(fields[0]);
                        std::string name_txt = fields[1];
                        std::string name_class = fields[3];
                        
                        if (name_class == "scientific name" && 
                            taxon_parents.find(taxon_id) != taxon_parents.end()) {
                            taxon_names[taxon_id] = name_txt;
                            names_loaded++;
                        }
                    } catch (const std::exception& e) {
                        continue;
                    }
                }
            }
            names_in.close();
            
            std::cout << "Loaded " << names_loaded << " scientific names" << std::endl;
        }
        
        return nodes_loaded > 0;
    }
    
    bool save_database() {
        std::cout << "Saving database to " << output_directory << "..." << std::endl;
        
        // Merge and deduplicate LCA candidates
        std::unordered_map<uint64_t, LCACandidate> unique_candidates;
        
        for (const auto& candidate : all_lca_candidates) {
            if (unique_candidates.find(candidate.minimizer_hash) == unique_candidates.end()) {
                unique_candidates[candidate.minimizer_hash] = candidate;
            } else {
                // Update genome count for existing minimizer
                unique_candidates[candidate.minimizer_hash].genome_count++;
                unique_candidates[candidate.minimizer_hash].uniqueness_score = 
                    1.0f / unique_candidates[candidate.minimizer_hash].genome_count;
            }
        }
        
        stats.unique_minimizers = unique_candidates.size();
        
        // Save hash table
        std::string hash_file = output_directory + "/hash_table.k2d";
        std::ofstream hash_out(hash_file, std::ios::binary);
        
        if (!hash_out.is_open()) {
            std::cerr << "Cannot create hash table file: " << hash_file << std::endl;
            return false;
        }
        
        uint64_t table_size = unique_candidates.size() * 2;  // 50% load factor
        uint64_t num_entries = unique_candidates.size();
        
        hash_out.write(reinterpret_cast<const char*>(&table_size), sizeof(uint64_t));
        hash_out.write(reinterpret_cast<const char*>(&num_entries), sizeof(uint64_t));
        
        for (const auto& [hash, candidate] : unique_candidates) {
            hash_out.write(reinterpret_cast<const char*>(&candidate.minimizer_hash), sizeof(uint64_t));
            hash_out.write(reinterpret_cast<const char*>(&candidate.lca_taxon), sizeof(uint32_t));
            hash_out.write(reinterpret_cast<const char*>(&candidate.genome_count), sizeof(uint32_t));
            hash_out.write(reinterpret_cast<const char*>(&candidate.uniqueness_score), sizeof(float));
        }
        hash_out.close();
        
        // Save taxonomy
        std::string taxonomy_file = output_directory + "/taxonomy.tsv";
        std::ofstream tax_out(taxonomy_file);
        
        tax_out << "taxon_id\tname\tparent_id\n";
        for (const auto& [taxon_id, name] : taxon_names) {
            uint32_t parent_id = taxon_parents.count(taxon_id) ? taxon_parents[taxon_id] : 0;
            tax_out << taxon_id << "\t" << name << "\t" << parent_id << "\n";
        }
        tax_out.close();
        
        // Save build parameters
        std::string params_file = output_directory + "/build_params.txt";
        std::ofstream params_out(params_file);
        params_out << "k=" << params.k << "\n";
        params_out << "ell=" << params.ell << "\n";
        params_out << "spaces=" << params.spaces << "\n";
        params_out << "xor_mask=0x" << std::hex << params.xor_mask << "\n";
        params_out.close();
        
        std::cout << "Database saved successfully!" << std::endl;
        std::cout << "  Hash table: " << hash_file << " (" << num_entries << " entries)" << std::endl;
        std::cout << "  Taxonomy: " << taxonomy_file << " (" << taxon_names.size() << " taxa)" << std::endl;
        
        return true;
    }
};

// ================================================================
// MAIN FUNCTION AND USAGE
// ================================================================

int main(int argc, char* argv[]) {
    if (argc < 3) {
        std::cout << "GPU Kraken2-style Database Builder\n";
        std::cout << "Usage: " << argv[0] << " <genome_dir> <output_dir> [taxonomy_dir]\n\n";
        std::cout << "Arguments:\n";
        std::cout << "  genome_dir   - Directory containing FASTA genome files (.fna, .fa, .fasta)\n";
        std::cout << "  output_dir   - Output directory for database files\n";
        std::cout << "  taxonomy_dir - Optional: Directory containing NCBI taxonomy files\n\n";
        std::cout << "Example:\n";
        std::cout << "  " << argv[0] << " ./genomes ./my_database ./taxonomy\n";
        return 1;
    }
    
    std::string genome_dir = argv[1];
    std::string output_dir = argv[2];
    std::string taxonomy_dir = (argc > 3) ? argv[3] : "";
    
    // Check CUDA device
    int device_count;
    cudaGetDeviceCount(&device_count);
    if (device_count == 0) {
        std::cerr << "No CUDA devices found!" << std::endl;
        return 1;
    }
    
    cudaDeviceProp prop;
    cudaGetDeviceProperties(&prop, 0);
    std::cout << "Using GPU: " << prop.name << std::endl;
    std::cout << "GPU Memory: " << (prop.totalGlobalMem / 1024 / 1024) << " MB" << std::endl;
    
    std::cout << "\n=== GPU KRAKEN2 DATABASE BUILDER ===" << std::endl;
    std::cout << "Genome directory: " << genome_dir << std::endl;
    std::cout << "Output directory: " << output_dir << std::endl;
    if (!taxonomy_dir.empty()) {
        std::cout << "Taxonomy directory: " << taxonomy_dir << std::endl;
    }
    
    // Use Kraken2 default parameters
    MinimizerParams params = MinimizerParams::kraken2_defaults();
    GPUKraken2DatabaseBuilder builder(output_dir, params);
    
    bool success = builder.build_database_from_genomes(genome_dir, taxonomy_dir);
    
    if (success) {
        std::cout << "\nðŸŽ‰ Database build completed successfully!" << std::endl;
        std::cout << "\nDatabase files created in: " << output_dir << std::endl;
        std::cout << "  - hash_table.k2d   (minimizer hash table)" << std::endl;
        std::cout << "  - taxonomy.tsv      (taxonomy mapping)" << std::endl;
        std::cout << "  - build_params.txt  (build parameters)" << std::endl;
        return 0;
    } else {
        std::cout << "\nâŒ Database build failed!" << std::endl;
        return 1;
    }
}

/*
COMPILATION:
nvcc -std=c++17 -O3 -arch=sm_70 gpu_kraken2_database_builder_integrated.cu -o gpu_kraken2_builder

USAGE:
./gpu_kraken2_builder ./genome_directory ./output_database_directory [./taxonomy_directory]

KEY FEATURES:
1. âœ… Proper Kraken2-style minimizer extraction with sliding window
2. âœ… Sequential deduplication (only store minimizers that differ from previous)
3. âœ… Canonical hashing with reverse complement
4. âœ… Spaced seed support (Kraken2 default: spaces=7)
5. âœ… Memory-efficient GPU processing with batching
6. âœ… Complete database output compatible with classification pipelines
7. âœ… Comprehensive statistics and compression reporting
8. âœ… Proper error handling and memory management

The key fix is in extract_minimizer_kraken2_style() and the kernel that only stores
minimizers when they differ from the previous one (last_minimizer tracking).
This creates the compression that Kraken2 is known for.
*/
# alright we're starting with a new profiler workflow at runtime/kernels/profiler
# We now split out CMakeLists.txt into the individual directories so the build locations will be within the kernel subdirectories

# You're in /runtime/kernels/profiler

# 1. Create a build directory
mkdir build
cd build

# 2. Run CMake to configure the project
cmake ..

# 3. Build everything
make -j4  # The -j4 uses 4 CPU cores for faster compilation

# Or build specific targets:
make test_minimizer         # Just the minimizer test
make test_fastq_pipeline    # Just the FASTQ pipeline
make hybrid_profiler_pipeline  # Just the hybrid profiler

# Test with synthetic data (1000 sequences)
./test_minimizer

# Test with your own FASTQ file
./test_minimizer /path/to/your/reads.fastq

# Run benchmark mode (10,000 sequences)
./test_minimizer --benchmark

# Process a FASTQ file (can be gzipped)
./test_fastq_pipeline ../../../../1M_synthetic_reads_R1.fastq.gz

# Or uncompressed (though compressed reads run fine - except got stalled)
zcat ../../../../1M_synthetic_reads_R1.fastq.gz > test_reads.fastq
./test_fastq_pipeline test_reads.fastq

# This needs a Kraken2 database
./hybrid_profiler_pipeline /path/to/kraken2_db /path/to/reads.fastq

./hybrid_profiler_pipeline /home/david/Databases/Kraken2DB data/569_A_038_R1.fastq.gz 


# get genomes from NCBI and process kmers (default 31 with stride 5)
python src/python/download_microbial_genomes.py data/pathogen_db --email dbhaslam@gmail.com --genomes-per-species 10 --k 31 --stride 5

# next convert the db to binary
cd runtime/kernels/profiler/build
./build_db_from_kmers /data/pathogen_db/database_kmers.txt /data/pathogen_db/pathogen.db

# for now test as below (hybrid_profiler_pipeline is for kraken style db):
# need to build 
./runtime/kernels/profiler/build/gpu_profiler_pipeline data/pathogen_db/ data/569_A_038_R1.fastq.gz \
    data/569_A_038_R2.fastq.gz --output-prefix data/569_A_038_profile



● Bash(cd ~/Documents/Code/biogpu/runtime/kernels/profiler/build && ./build_db_from_kmers
      ~/Documents/Code/biogpu/data/pathogen_db/database_kmers.txt ~/Documents/Code/…)
  ⎿  Building GPU k-mer database from /home/david/Documents/Code/biogpu/data/pathogen_db/database_kmers.txt...
       Processed 100000 k-mers...
       Processed 200000 k-mers...
       Processed 300000 k-mers...
     … +741 lines (ctrl+r to expand)

● Success! The database has been built. It processed 72,631,855 k-mers from 28,901 different taxa and created a GPU hash table with
   134,217,728 buckets. The database is now saved at /home/david/Documents/Code/biogpu/data/pathogen_db/pathogen.db and uses 16GB
  of memory.

  You can now use this database with the gpu_profiler_pipeline command as shown in the output.

  ● The GPU profiler encountered a CUDA error. This could be due to several reasons. Let me check a few things:

● Bash(nvidia-smi)
  ⎿  Thu Jun 12 08:45:15 2025
     +-----------------------------------------------------------------------------------------+
     | NVIDIA-SMI 570.133.07             Driver Version: 570.133.07     CUDA Version: 12.8     |
     |-----------------------------------------+------------------------+----------------------+
     … +24 lines (ctrl+r to expand)

● I see there's already a test_fastq_pipeline process using both GPUs. The database requires 16GB but each TITAN Xp only has 12GB.
  Let me check if we need to specify a GPU or if there's a smaller database option:

● Bash(cd ~/Documents/Code/biogpu && ./runtime/kernels/profiler/build/gpu_profiler_pipeline --help 2>&1 | head -50)
  ⎿ Usage: ./runtime/kernels/profiler/build/gpu_profiler_pipeline <database.bin> <reads.fastq> [reads2.fastq] [--output-prefix
    PREFIX]
      Single-end mode: provide one FASTQ file
      Paired-end mode: provide two FASTQ files (R1 and R2)
      --output-prefix: Prefix for output files (default: microbiome_profile)

● The issue is that the database (16GB) is larger than the GPU memory (12GB per card). Let me check if there's a smaller test
  database or if we need to create one: